{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Recognition Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import json\n",
    "from types import SimpleNamespace\n",
    "import seaborn; seaborn.set()\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "MODELS_DIR = 'models/'\n",
    "MODEL_TF = MODELS_DIR + 'model'\n",
    "MODEL_TFLITE = MODELS_DIR + 'model.tflite'\n",
    "MODEL_TFLITE_MICRO = MODELS_DIR + 'model.cc'\n",
    "# TensorFlow is an open source machine learning library\n",
    "\n",
    "#from micromlgen import port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 238, 319, 8)       152       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 236, 318, 16)      784       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 118, 159, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 116, 158, 16)      1552      \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 114, 157, 8)       776       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 57, 78, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 57, 78, 8)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 35568)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                2276416   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 9)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,289,161\n",
      "Trainable params: 2,289,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(8, (3, 2), activation='relu', input_shape=(240, 320, 3)))\n",
    "model.add(Conv2D(16, (3, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(16, (3, 2), activation='relu'))\n",
    "model.add(Conv2D(8, (3, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(9, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image and Config Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads an image and its cfg file\n",
    "def importImage(path, X, Y):\n",
    "    #Load the image\n",
    "    img = load_img(path)\n",
    "    arr = img_to_array(img)\n",
    "    \n",
    "    #Load the cfg\n",
    "    configFile = open(path[:-4] + '.cfg')\n",
    "    configRaw = configFile.read()\n",
    "    config = json.loads(configRaw, object_hook=lambda d: SimpleNamespace(**d)) \n",
    "    \n",
    "    cfgArr = [config.valid, config.x1, config.y1, config.x2, config.y2, config.x3, config.y3, config.x4, config.y4]\n",
    "    X.append(arr)\n",
    "    Y.append(cfgArr)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAllTrainingData(data_path):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for root, dirs, files in os.walk(data_path, topdown=False):\n",
    "        for f in files:\n",
    "            if (f.endswith(\".jpg\")):\n",
    "                X, Y = importImage(os.path.join(root, f), X, Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrainingValidation(X, Y, split_size=0.2):\n",
    "    if len(X) == len(Y):\n",
    "        splitCount = int(len(X) * split_size)\n",
    "        \n",
    "        used_indices = []\n",
    "        \n",
    "        X_set = []\n",
    "        X_val = []\n",
    "        Y_set = []\n",
    "        Y_val = []\n",
    "        \n",
    "        while len(X_val) < splitCount:\n",
    "            index = random.randint(0, len(X)-1)\n",
    "            if index not in used_indices:\n",
    "                X_val.append(X[index])\n",
    "                Y_val.append(Y[index])\n",
    "                used_indices.append(index)\n",
    "        \n",
    "        for i in range(0, len(X)-1):\n",
    "            if i not in used_indices:\n",
    "                X_set.append(X[i])\n",
    "                Y_set.append(Y[i])\n",
    "                \n",
    "        return np.array(X_set), np.array(Y_set), np.array(X_val), np.array(Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Training Data and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   ...\n",
      "   [ 3.  3.  3.]\n",
      "   [ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]]\n",
      "\n",
      "  [[ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   ...\n",
      "   [ 3.  3.  3.]\n",
      "   [ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]]\n",
      "\n",
      "  [[ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   ...\n",
      "   [ 3.  3.  3.]\n",
      "   [ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[22. 22. 22.]\n",
      "   [23. 23. 23.]\n",
      "   [24. 24. 24.]\n",
      "   ...\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]]\n",
      "\n",
      "  [[20. 20. 20.]\n",
      "   [21. 21. 21.]\n",
      "   [22. 22. 22.]\n",
      "   ...\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]]\n",
      "\n",
      "  [[18. 18. 18.]\n",
      "   [19. 19. 19.]\n",
      "   [20. 20. 20.]\n",
      "   ...\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]]]\n",
      "\n",
      "\n",
      " [[[ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   ...\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]]\n",
      "\n",
      "  [[ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   ...\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]]\n",
      "\n",
      "  [[ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   ...\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[38. 38. 38.]\n",
      "   [39. 39. 39.]\n",
      "   [39. 39. 39.]\n",
      "   ...\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]]\n",
      "\n",
      "  [[38. 38. 38.]\n",
      "   [38. 38. 38.]\n",
      "   [39. 39. 39.]\n",
      "   ...\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]]\n",
      "\n",
      "  [[37. 37. 37.]\n",
      "   [38. 38. 38.]\n",
      "   [38. 38. 38.]\n",
      "   ...\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]]]\n",
      "\n",
      "\n",
      " [[[ 8.  8.  8.]\n",
      "   [ 8.  8.  8.]\n",
      "   [ 8.  8.  8.]\n",
      "   ...\n",
      "   [ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]]\n",
      "\n",
      "  [[ 8.  8.  8.]\n",
      "   [ 8.  8.  8.]\n",
      "   [ 8.  8.  8.]\n",
      "   ...\n",
      "   [ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]]\n",
      "\n",
      "  [[ 8.  8.  8.]\n",
      "   [ 8.  8.  8.]\n",
      "   [ 8.  8.  8.]\n",
      "   ...\n",
      "   [ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[35. 35. 35.]\n",
      "   [37. 37. 37.]\n",
      "   [39. 39. 39.]\n",
      "   ...\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]]\n",
      "\n",
      "  [[36. 36. 36.]\n",
      "   [37. 37. 37.]\n",
      "   [40. 40. 40.]\n",
      "   ...\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]]\n",
      "\n",
      "  [[38. 38. 38.]\n",
      "   [39. 39. 39.]\n",
      "   [41. 41. 41.]\n",
      "   ...\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 8.  8.  8.]\n",
      "   [ 8.  8.  8.]\n",
      "   [ 8.  8.  8.]\n",
      "   ...\n",
      "   [ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]]\n",
      "\n",
      "  [[ 8.  8.  8.]\n",
      "   [ 8.  8.  8.]\n",
      "   [ 8.  8.  8.]\n",
      "   ...\n",
      "   [ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]]\n",
      "\n",
      "  [[ 8.  8.  8.]\n",
      "   [ 8.  8.  8.]\n",
      "   [ 8.  8.  8.]\n",
      "   ...\n",
      "   [ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[40. 40. 40.]\n",
      "   [42. 42. 42.]\n",
      "   [44. 44. 44.]\n",
      "   ...\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]]\n",
      "\n",
      "  [[40. 40. 40.]\n",
      "   [42. 42. 42.]\n",
      "   [44. 44. 44.]\n",
      "   ...\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]]\n",
      "\n",
      "  [[40. 40. 40.]\n",
      "   [42. 42. 42.]\n",
      "   [44. 44. 44.]\n",
      "   ...\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]\n",
      "   [ 4.  4.  4.]]]\n",
      "\n",
      "\n",
      " [[[22. 22. 22.]\n",
      "   [23. 23. 23.]\n",
      "   [25. 25. 25.]\n",
      "   ...\n",
      "   [ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]]\n",
      "\n",
      "  [[23. 23. 23.]\n",
      "   [24. 24. 24.]\n",
      "   [25. 25. 25.]\n",
      "   ...\n",
      "   [ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]]\n",
      "\n",
      "  [[23. 23. 23.]\n",
      "   [24. 24. 24.]\n",
      "   [25. 25. 25.]\n",
      "   ...\n",
      "   [ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[50. 50. 50.]\n",
      "   [49. 49. 49.]\n",
      "   [48. 48. 48.]\n",
      "   ...\n",
      "   [21. 21. 21.]\n",
      "   [22. 22. 22.]\n",
      "   [23. 23. 23.]]\n",
      "\n",
      "  [[52. 52. 52.]\n",
      "   [51. 51. 51.]\n",
      "   [50. 50. 50.]\n",
      "   ...\n",
      "   [20. 20. 20.]\n",
      "   [20. 20. 20.]\n",
      "   [21. 21. 21.]]\n",
      "\n",
      "  [[55. 55. 55.]\n",
      "   [54. 54. 54.]\n",
      "   [53. 53. 53.]\n",
      "   ...\n",
      "   [19. 19. 19.]\n",
      "   [19. 19. 19.]\n",
      "   [19. 19. 19.]]]\n",
      "\n",
      "\n",
      " [[[ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   ...\n",
      "   [ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]]\n",
      "\n",
      "  [[ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   ...\n",
      "   [ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]]\n",
      "\n",
      "  [[ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   [ 6.  6.  6.]\n",
      "   ...\n",
      "   [ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[40. 40. 40.]\n",
      "   [44. 44. 44.]\n",
      "   [47. 47. 47.]\n",
      "   ...\n",
      "   [20. 20. 20.]\n",
      "   [20. 20. 20.]\n",
      "   [20. 20. 20.]]\n",
      "\n",
      "  [[40. 40. 40.]\n",
      "   [44. 44. 44.]\n",
      "   [47. 47. 47.]\n",
      "   ...\n",
      "   [20. 20. 20.]\n",
      "   [20. 20. 20.]\n",
      "   [20. 20. 20.]]\n",
      "\n",
      "  [[40. 40. 40.]\n",
      "   [44. 44. 44.]\n",
      "   [47. 47. 47.]\n",
      "   ...\n",
      "   [20. 20. 20.]\n",
      "   [20. 20. 20.]\n",
      "   [20. 20. 20.]]]]\n",
      "[[  1  39  51 279  56  29 206 288 208]\n",
      " [  1  28  44 284  23  40 197 293 186]\n",
      " [  1  19  26 299  28  25 201 300 196]\n",
      " [  1  40  35 285  35  43 189 286 184]\n",
      " [  1  41  88 243  29  72 213 282 156]\n",
      " [  1  40  69 255  62   3 209 309 186]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  1  73  46 274  81   6 156 293 207]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  1  20  38 284  26   5 201 302 203]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  1  39  84 227  69  37 204 247 186]\n",
      " [  1  28  59 277  42  24 215 299 204]\n",
      " [  1  22  90 221  24  53 225 285 137]\n",
      " [  1  89  40 278  67  54 148 259 195]\n",
      " [  1  27  47 272  29  22 202 298 185]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  1  22  37 287  36  20 205 295 202]\n",
      " [  1  39  56 268  39  47 193 273 186]\n",
      " [  1  26  44 278  32  33 199 286 189]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  1  28  92 231  22  72 220 281 143]\n",
      " [  1 114  15 293  98  58 127 252 209]\n",
      " [  1  30  40 282  19  41 196 297 176]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  1  33  78 255  48  42 218 283 189]\n",
      " [  1  52  45 263  39  49 174 268 173]\n",
      " [  1  41  77 234  28  67 196 266 150]\n",
      " [  1  66  66 267  86  41 190 266 216]\n",
      " [  1  30  34 279  15  32 188 301 172]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  1  52  46 272  48  50 183 275 184]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  1  37  37 277  38  31 187 284 187]\n",
      " [  1  32  66 247  34  48 199 272 168]\n",
      " [  1  47  50 251  47  46 178 259 172]\n",
      " [  1  71  22 278  69  33 149 257 199]\n",
      " [  1  38  93 242  10  82 223 305 136]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  1  43  48 268  41  42 186 276 183]\n",
      " [  1  29  54 288  51  28 212 290 216]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  1  45  42 274  38  40 182 270 185]\n",
      " [  1  45  40 286  39  32 186 282 196]\n",
      " [  1  46 117 215  12  93 223 281 129]\n",
      " [  1  37  75 245  21  72 203 279 151]\n",
      " [  1  44  37 248  32  39 161 248 161]\n",
      " [  1  31  35 290  35  30 202 292 190]\n",
      " [  1  52  66 281  61  51 210 282 203]\n",
      " [  1  33  26 301  28  33 193 294 190]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  1  48  41 283  37  50 184 283 185]\n",
      " [  1  50  42 277  46  45 181 273 190]\n",
      " [  1  19  33 296  28  17 201 299 205]\n",
      " [  1  37  41 293  35  33 198 299 200]\n",
      " [  1  26  84 245  22  65 219 283 158]\n",
      " [  1  98  23 291  85  45 138 267 207]\n",
      " [  1  56  54 285  51  52 201 300 193]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  1  48  46 271  42  45 185 278 182]\n",
      " [  1  75  28 272  64  44 148 257 188]\n",
      " [  1  46  40 278  19  54 186 302 162]\n",
      " [  1  36  34 266  33  33 178 270 178]\n",
      " [  1  29  32 280  33  29 191 287 186]\n",
      " [  1  31  61 272  47  35 216 292 196]\n",
      " [  1  63  31 293  65  34 176 284 210]\n",
      " [  1  24  48 276  41  31 213 291 193]\n",
      " [  1  58  48 280  41  67 190 291 175]\n",
      " [  1  18  75 246   6  61 219 295 146]\n",
      " [  1  47  50 252  43  53 181 263 166]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  1  45  50 286  40  47 205 304 188]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  1  88  19 297  93  26 148 270 229]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  1  57  45 287  40  60 190 296 182]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  1  45  22 290  16  46 170 294 171]\n",
      " [  1  33  39 296  38  36 201 298 202]\n",
      " [  1  48  38 277  41  46 183 283 182]\n",
      " [  1  30  36 274  34  32 190 281 184]]\n",
      "(21, 240, 320, 3)\n",
      "(21, 9)\n"
     ]
    }
   ],
   "source": [
    "X, Y = loadAllTrainingData(\"../Training Data Preprocessing/Training Data/Grid\")\n",
    "X, Y, X_val, Y_val = splitTrainingValidation(X, Y, split_size=0.2)\n",
    "\n",
    "print(X)\n",
    "print(Y)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11/11 [==============================] - 2s 173ms/step - loss: 6257.3540 - accuracy: 0.4651 - val_loss: 1617.6346 - val_accuracy: 0.6190\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 3044.5767 - accuracy: 0.3837 - val_loss: 1302.8861 - val_accuracy: 0.7143\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 2s 160ms/step - loss: 2261.1445 - accuracy: 0.5930 - val_loss: 1221.6605 - val_accuracy: 0.6190\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 1262.0475 - accuracy: 0.5814 - val_loss: 1903.3987 - val_accuracy: 0.4286\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 712.2219 - accuracy: 0.5814 - val_loss: 832.2415 - val_accuracy: 0.7143\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 337.8132 - accuracy: 0.6163 - val_loss: 786.8715 - val_accuracy: 0.5238\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 241.3812 - accuracy: 0.5698 - val_loss: 961.6491 - val_accuracy: 0.5238\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 2s 164ms/step - loss: 167.7533 - accuracy: 0.6512 - val_loss: 1033.0099 - val_accuracy: 0.6667\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 133.0828 - accuracy: 0.5116 - val_loss: 1052.5295 - val_accuracy: 0.6667\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 93.4298 - accuracy: 0.6744 - val_loss: 1098.9290 - val_accuracy: 0.6190\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 79.5063 - accuracy: 0.6047 - val_loss: 1267.7104 - val_accuracy: 0.6190\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 127.3030 - accuracy: 0.7093 - val_loss: 1347.2960 - val_accuracy: 0.5714\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 2s 163ms/step - loss: 129.6035 - accuracy: 0.6279 - val_loss: 669.3077 - val_accuracy: 0.7619\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 163.4075 - accuracy: 0.6860 - val_loss: 655.0018 - val_accuracy: 0.6667\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 143.4393 - accuracy: 0.6744 - val_loss: 711.9583 - val_accuracy: 0.6667\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 171.6524 - accuracy: 0.6977 - val_loss: 1074.3567 - val_accuracy: 0.5714\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 212.6721 - accuracy: 0.7093 - val_loss: 1291.2142 - val_accuracy: 0.7143\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 2s 163ms/step - loss: 165.7593 - accuracy: 0.6512 - val_loss: 939.5052 - val_accuracy: 0.7143\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 95.2426 - accuracy: 0.6628 - val_loss: 936.6598 - val_accuracy: 0.6190\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 68.4596 - accuracy: 0.6512 - val_loss: 1148.9636 - val_accuracy: 0.7619\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 77.2456 - accuracy: 0.7326 - val_loss: 1077.3503 - val_accuracy: 0.7619\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 2s 163ms/step - loss: 69.4647 - accuracy: 0.6860 - val_loss: 772.7443 - val_accuracy: 0.6190\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 76.9455 - accuracy: 0.7326 - val_loss: 902.7539 - val_accuracy: 0.6190\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 69.4752 - accuracy: 0.7558 - val_loss: 1115.9319 - val_accuracy: 0.7619\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 59.2109 - accuracy: 0.6977 - val_loss: 927.1508 - val_accuracy: 0.6667\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 57.4414 - accuracy: 0.6744 - val_loss: 874.1561 - val_accuracy: 0.7619\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 56.5431 - accuracy: 0.7326 - val_loss: 1014.7111 - val_accuracy: 0.6667\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 2s 163ms/step - loss: 94.7565 - accuracy: 0.7209 - val_loss: 901.6669 - val_accuracy: 0.6190\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 67.1249 - accuracy: 0.6860 - val_loss: 995.2156 - val_accuracy: 0.7143\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 75.8700 - accuracy: 0.6977 - val_loss: 1097.9222 - val_accuracy: 0.8095\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 106.8959 - accuracy: 0.7326 - val_loss: 709.9634 - val_accuracy: 0.7143\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 76.9939 - accuracy: 0.7093 - val_loss: 1014.0733 - val_accuracy: 0.7143\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 61.9305 - accuracy: 0.6977 - val_loss: 1000.9671 - val_accuracy: 0.7619\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 71.6002 - accuracy: 0.6977 - val_loss: 1057.7931 - val_accuracy: 0.7143\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 48.0989 - accuracy: 0.6395 - val_loss: 1029.1342 - val_accuracy: 0.8095\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 2s 163ms/step - loss: 51.3700 - accuracy: 0.7209 - val_loss: 915.3514 - val_accuracy: 0.7143\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 54.5612 - accuracy: 0.6977 - val_loss: 923.9609 - val_accuracy: 0.7143\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 48.6659 - accuracy: 0.7209 - val_loss: 692.6130 - val_accuracy: 0.8095\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 52.1447 - accuracy: 0.7442 - val_loss: 1152.2460 - val_accuracy: 0.6190\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 82.5622 - accuracy: 0.7209 - val_loss: 769.7620 - val_accuracy: 0.7619\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 99.5965 - accuracy: 0.7442 - val_loss: 769.0265 - val_accuracy: 0.6667\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 119.5359 - accuracy: 0.6628 - val_loss: 1439.7678 - val_accuracy: 0.8095\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 2s 160ms/step - loss: 149.4111 - accuracy: 0.6744 - val_loss: 740.1708 - val_accuracy: 0.6667\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 2s 163ms/step - loss: 210.4722 - accuracy: 0.6860 - val_loss: 842.9037 - val_accuracy: 0.4762\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 2s 163ms/step - loss: 148.4165 - accuracy: 0.7558 - val_loss: 1090.8795 - val_accuracy: 0.8095\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 127.4875 - accuracy: 0.6860 - val_loss: 693.6500 - val_accuracy: 0.6667\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 67.4170 - accuracy: 0.6512 - val_loss: 1034.4885 - val_accuracy: 0.7619\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 61.6170 - accuracy: 0.7093 - val_loss: 823.7916 - val_accuracy: 0.8095\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 2s 164ms/step - loss: 45.9427 - accuracy: 0.6860 - val_loss: 777.0954 - val_accuracy: 0.7619\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 2s 163ms/step - loss: 50.3925 - accuracy: 0.7674 - val_loss: 891.9323 - val_accuracy: 0.7619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d686cd2748>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=0.01)\n",
    "\n",
    "model.fit(X, Y, epochs=50, validation_data=(X_val, Y_val), batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Random Images\n",
    "\n",
    "Try changing the sample number below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 42, 41, 271, 34, 41, 184, 283, 180]]\n",
      "[[1, 41, 43, 284, 37, 45, 193, 291, 189]]\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "Y_test = []\n",
    "X_test, Y_test = importImage(\"../Training Data Preprocessing/Training Data/Grid/sample_98.jpg\", X_test, Y_test)\n",
    "X_test = np.array(X_test)\n",
    "Y_predict = model.predict(X_test)\n",
    "Y_predict = [[round(Y_predict[0][0]), round(Y_predict[0][1]), round(Y_predict[0][2]), round(Y_predict[0][3]), round(Y_predict[0][4]), round(Y_predict[0][5]), round(Y_predict[0][6]), round(Y_predict[0][7]), round(Y_predict[0][8])]]\n",
    "print(Y_predict)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2295936"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save(MODEL_TF)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.allow_custom_ops = True\n",
    "\n",
    "\n",
    "def respresentative_dataset_gen():\n",
    "    img = tf.data.Dataset.from_tensor_slices(X).batch(1)\n",
    "    for i in img.take(30):\n",
    "        yield [i]\n",
    "        \n",
    "converter.representative_dataset = respresentative_dataset_gen\n",
    "\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "\n",
    "\n",
    "model_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(MODEL_TFLITE, \"wb\").write(model_tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install xxd if it is not available\n",
    "!apt-get update && apt-get -qq install xxd\n",
    "# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
    "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
    "# Update variable names\n",
    "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
    "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
